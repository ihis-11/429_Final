{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9283810-1cc3-400b-ab0d-2b29ad77917f",
   "metadata": {},
   "source": [
    "### Finetuning and training the Pytorch-i3d model\n",
    "Code taken from: https://github.com/piergiaj/pytorch-i3d/blob/master/train_i3d.py \n",
    "\n",
    "Note: This code was written for PyTorch 0.3. Version 0.4 and newer may cause issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbf0b21-10bf-490d-9dd2-95e35d3114e6",
   "metadata": {},
   "source": [
    "To-dos:\n",
    "1. extract videos and add labels (the line `return images, 0` assigns the label 0 to every images in the code for class `Dataset`. I have chosen the top few single-class labels in `preprocess.ipynb`, see the last cell to get the labels and associated videos through the video names, `v_names`)\n",
    "2. streamline process for training pre-trained model (loaded via `i3d.load_state_dict(torch.load('rgb_imagenet.pt'))`) (possibly creating a .py script, no need to change layers yet)\n",
    "3. run the baseline model and record baseline performance\n",
    "4. write the code for editing layers in the pretrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6501e6-193d-4edf-a388-1ea00a5a9f81",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56422195-b081-4f3d-8b9a-8d541d0bad5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, precision_score\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='1'\n",
    "# os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:<1024>\"\n",
    "import sys\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import videotransforms\n",
    "import numpy as np\n",
    "from pytorch_i3d import InceptionI3d\n",
    "import numpy as np\n",
    "import glob\n",
    "import random\n",
    "from tensorboardX import SummaryWriter\n",
    "from preprocess import holdout_set\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d266b6f0-d337-4648-b968-9764891edef7",
   "metadata": {},
   "source": [
    "# Construct a dataset class for training the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a76d20a-aa79-438d-95f9-b62477c305b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, paths, v_names, v_labels, num_samples=16): # num_samples cannot be lower than 16\n",
    "        self.num_samples = num_samples\n",
    "        self.frames = dict()\n",
    "        for p in paths:\n",
    "            self.frames[p] = sorted(glob.glob(p+\"/*.jpg\"))\n",
    "        self.data = paths\n",
    "        self.video_names = v_names\n",
    "        self.video_labels = v_labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        p = self.data[idx]\n",
    "        num_frames = len(self.frames[p])-1\n",
    "        sampled_idx = np.linspace(0, num_frames, self.num_samples) #get num_samples frames from the video\n",
    "        images = []\n",
    "        index = np.where(self.video_names == p.split('/')[-1]) #index of p's video name in video_names\n",
    "        label_video = self.video_labels[index] # the labels for the video\n",
    "        for i in sampled_idx:\n",
    "            image = torchvision.io.read_image(self.frames[p][int(i)])\n",
    "            small_dim = min(image.shape[-2:])\n",
    "            image = torchvision.transforms.functional.center_crop(image, (small_dim, small_dim))\n",
    "            image = torchvision.transforms.functional.resize(image, (224, 224), antialias=True)\n",
    "            images.append(image)\n",
    "        images = torch.stack(images, axis=1)\n",
    "        images = (images/255)*2 - 1 #values are between -1 and 1\n",
    "        return images, label_video "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4ed965-0b85-44f6-97bc-25383f510cf8",
   "metadata": {},
   "source": [
    "# Extract data and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31b8f33d-88ce-487f-be31-ac12c2487082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creating_datasets():\n",
    "    video_train, video_val, label_train, label_val, unique_labels = holdout_set(0.25) #valid names and videos\n",
    "    batch_size = 10 # batch size in training\n",
    "    num_videos_train = len(video_train)\n",
    "    num_videos_val = len(video_val)\n",
    "    num_classes = len(set(label_train)) #count unique in labels\n",
    "\n",
    "    video_frames_path = \"/scratch/network/hishimwe/image\" \n",
    "    # only extract the videos with v_names and v_labels from preprocess.ipynb \n",
    "    paths = glob.glob(video_frames_path+\"/*\")\n",
    "    random.seed(0)\n",
    "    random.shuffle(paths)\n",
    "\n",
    "    good_paths_train = list(filter(lambda c: c.split('/')[-1] in video_train, paths)) #should only get path where good video name; not sure if this filtering will work \n",
    "    good_paths_val = list(filter(lambda c: c.split('/')[-1] in video_val, paths)) # validation video paths \n",
    "\n",
    "    d_train = dataset(paths=good_paths_train, v_names=video_train, v_labels= label_train)\n",
    "    d_val = dataset(paths=good_paths_val, v_names=video_val, v_labels= label_val)\n",
    "\n",
    "    loader_train = torch.utils.data.DataLoader(d_train, shuffle=True, batch_size=batch_size, drop_last=False, num_workers=4)\n",
    "    loader_val = torch.utils.data.DataLoader(d_val, shuffle=True, batch_size=batch_size, drop_last=False, num_workers=4)\n",
    "    \n",
    "    return loader_train, loader_val, unique_labels, num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9aef6b0-74db-4430-b114-ff98293d9c23",
   "metadata": {},
   "source": [
    "# Construct the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79d5aef8-0ec0-4f25-b834-bad03e2fb320",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 0.9679968357086182 seconds\n"
     ]
    }
   ],
   "source": [
    "loader_train, loader_val, unique_labels, num_classes = creating_datasets() \n",
    "\n",
    "start_time = time.time() \n",
    "i3d = InceptionI3d(400, in_channels=3) # first input is num_classes \n",
    "i3d.load_state_dict(torch.load('rgb_imagenet.pt'), strict=False) #added strict = false; theoretically this lets us add layers\n",
    "i3d.replace_logits(num_classes)\n",
    "i3d.cuda()\n",
    "\n",
    "print(f\"time taken: {time.time()-start_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2c9861-1c82-4c7b-a38d-ae5c9f609ee3",
   "metadata": {},
   "source": [
    "# Function to evaluate model performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97a26778",
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns accuracy, f1 score, average f1, and confusion matrix for the data\n",
    "def eval_metrics(ground_truth, predictions, num_classes):\n",
    "\n",
    "    #dictionary containing the accuracy, precision, f1, avg f1, and confusion matrix for the data\n",
    "    f1 = f1_score(y_true=ground_truth, y_pred=predictions, labels=np.arange(num_classes), average=None)\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(y_true=ground_truth, y_pred=predictions),\n",
    "        \"f1\": f1,\n",
    "        \"average f1\": np.mean(f1),\n",
    "        \"confusion matrix\": confusion_matrix(y_true=ground_truth, y_pred=predictions, labels=np.arange(num_classes)),\n",
    "        \"precision\": precision_score(y_true=ground_truth, y_pred=predictions, labels=np.arange(num_classes), average=None)\n",
    "        }\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45de9187-6c78-427c-a83e-e22f09b74f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, optimizer, loader, num_classes):\n",
    "    losses = []\n",
    "    ground_truth = []\n",
    "    predictions = []\n",
    "    for data, label in loader:\n",
    "        data = data.cuda()\n",
    "        label = label.squeeze().type(torch.LongTensor).cuda()\n",
    "        num_frames = data.size(2)\n",
    "        per_frame_logits = i3d(data).mean(2)\n",
    "        preds = per_frame_logits.cpu().detach().numpy().argmax(axis=1) # convert logits into predictions for evaluating accuracy\n",
    "        \n",
    "        # calculate and save loss\n",
    "        loss = F.cross_entropy(per_frame_logits, label)\n",
    "        losses.append(loss.item()) # append to losses\n",
    "        ground_truth.extend(list(label.cpu().detach().numpy()))\n",
    "        predictions.extend(preds.tolist())\n",
    "        \n",
    "        # perform gradient descent\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    metrics = eval_metrics(ground_truth, predictions, num_classes)   \n",
    "    return np.mean(losses), metrics # one loss per epoch and the corresponding metrics        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b890c9a1-9a31-4215-a69a-6abb12cf2bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, num_classes):\n",
    "    losses = []\n",
    "    ground_truth = []\n",
    "    predictions = []\n",
    "    for data, label in loader:\n",
    "        data = data.cuda()\n",
    "        label = label.squeeze().type(torch.LongTensor).cuda()\n",
    "        num_frames = data.size(2)\n",
    "        per_frame_logits = i3d(data).mean(2)\n",
    "        preds = per_frame_logits.cpu().detach().numpy().argmax(axis=1) # convert logits into predictions for evaluating accuracy\n",
    "        \n",
    "        # calculate and save loss\n",
    "        loss = F.cross_entropy(per_frame_logits, label)\n",
    "        losses.append(loss.item()) # append to losses\n",
    "        ground_truth.extend(list(label.cpu().detach().numpy()))\n",
    "        predictions.extend(preds.tolist())\n",
    "        \n",
    "    metrics = eval_metrics(ground_truth, predictions, num_classes)\n",
    "    return np.mean(losses), metrics # one loss per epoch and the corresponding metrics\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff9bb17-34d0-4a24-81c1-e9416b9f786e",
   "metadata": {},
   "source": [
    "# Train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dac52e08-f69e-47a4-ac7b-bedf0c8d70ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING STARTED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hishimwe/.conda/envs/new_429/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION ENDED\n",
      "Time taken for epoch 0: 3.6006507953008016 mins\n",
      "-----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hishimwe/.conda/envs/new_429/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# set up gradient descent params\n",
    "optimizer = optim.SGD(i3d.parameters(), lr=0.1, momentum=0.9, weight_decay=0.0000001) # weight_decay = l2 regularization\n",
    "lr_sched = optim.lr_scheduler.MultiStepLR(optimizer, [300, 1000])\n",
    "\n",
    "# set up training variables \n",
    "epochs = 10 \n",
    "\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "train_precisions = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "val_precisions = []\n",
    "\n",
    "# train\n",
    "for e in range(epochs):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # training\n",
    "    loss_train, metrics_train = training(model=i3d, optimizer=optimizer, loader=loader_train, num_classes=num_classes)\n",
    "    train_losses.append(loss_train)\n",
    "    train_accuracies.append(metrics_train[\"accuracy\"])\n",
    "    train_precisions.append(metrics_train[\"precision\"])\n",
    "    \n",
    "    print(\"TRAINING STARTED\")\n",
    "    # print(accuracy)\n",
    "    # print(precision)\n",
    "    \n",
    "    # validation \n",
    "    loss_val, metrics_val = evaluate(model=i3d, loader=loader_val, num_classes=num_classes)\n",
    "    val_losses.append(loss_val)\n",
    "    val_accuracies.append(metrics_val[\"accuracy\"])\n",
    "    val_precisions.append(metrics_val[\"precision\"])\n",
    "    \n",
    "    print(\"VALIDATION ENDED\")\n",
    "    # print(accuracy)\n",
    "    # print(precision)\n",
    "        \n",
    "    print(f\"Time taken for epoch {e}: {(time.time()-start_time)/60} mins\")\n",
    "    print(\"-----------------------------------------------------------------------\")\n",
    "\n",
    "np.savetxt('losses/train/train_10epochs', np.array(train_losses), delimiter=\",\")\n",
    "np.savetxt('losses/val/val_10epochs', np.array(val_losses), delimiter=\",\")\n",
    "\n",
    "np.savetxt('accuracies/train/train_10epochs', np.array(train_accuracies), delimiter=\",\")\n",
    "np.savetxt('accuracies/val/val_10epochs', np.array(val_accuracies), delimiter=\",\")\n",
    "\n",
    "np.savetxt('precisions/train/train_10epochs', np.array(train_precisions), delimiter=\",\")\n",
    "np.savetxt('precisions/val/val_10epochs', np.array(val_precisions), delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "076df6ef-fd45-4811-b842-8ed10732aeb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.210949840638116]\n",
      "[1.8080738201614255]\n",
      "[0.28309741881765194]\n",
      "[0.3860232945091514]\n"
     ]
    }
   ],
   "source": [
    "print(train_losses)\n",
    "print(val_losses)\n",
    "print(train_accuracies)\n",
    "print(val_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dbbf5c-9b13-4545-926a-59c5dcbc0ec3",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7409064-503b-4701-9739-636f2636e6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"models/baseline_val_testing\"\n",
    "torch.save(i3d, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df4bdf3-f866-4a5a-a02d-be2de8c3cada",
   "metadata": {},
   "source": [
    "Check saved output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23ba1e1c-03d6-4bf3-b004-2041ecd74a2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InceptionI3d(\n",
       "  (avg_pool): AvgPool3d(kernel_size=[2, 7, 7], stride=(1, 1, 1), padding=0)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (logits): Unit3D(\n",
       "    (conv3d): Conv3d(1024, 11, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "  )\n",
       "  (Conv3d_1a_7x7): Unit3D(\n",
       "    (conv3d): Conv3d(3, 64, kernel_size=(7, 7, 7), stride=(2, 2, 2), bias=False)\n",
       "    (bn): BatchNorm3d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (MaxPool3d_2a_3x3): MaxPool3dSamePadding(kernel_size=[1, 3, 3], stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (Conv3d_2b_1x1): Unit3D(\n",
       "    (conv3d): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "    (bn): BatchNorm3d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv3d_2c_3x3): Unit3D(\n",
       "    (conv3d): Conv3d(64, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), bias=False)\n",
       "    (bn): BatchNorm3d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (MaxPool3d_3a_3x3): MaxPool3dSamePadding(kernel_size=[1, 3, 3], stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (Mixed_3b): InceptionModule(\n",
       "    (b0): Unit3D(\n",
       "      (conv3d): Conv3d(192, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b1a): Unit3D(\n",
       "      (conv3d): Conv3d(192, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b1b): Unit3D(\n",
       "      (conv3d): Conv3d(96, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b2a): Unit3D(\n",
       "      (conv3d): Conv3d(192, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b2b): Unit3D(\n",
       "      (conv3d): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b3a): MaxPool3dSamePadding(kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (b3b): Unit3D(\n",
       "      (conv3d): Conv3d(192, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_3c): InceptionModule(\n",
       "    (b0): Unit3D(\n",
       "      (conv3d): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b1a): Unit3D(\n",
       "      (conv3d): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b1b): Unit3D(\n",
       "      (conv3d): Conv3d(128, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b2a): Unit3D(\n",
       "      (conv3d): Conv3d(256, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b2b): Unit3D(\n",
       "      (conv3d): Conv3d(32, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b3a): MaxPool3dSamePadding(kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (b3b): Unit3D(\n",
       "      (conv3d): Conv3d(256, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (MaxPool3d_4a_3x3): MaxPool3dSamePadding(kernel_size=[3, 3, 3], stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (Mixed_4b): InceptionModule(\n",
       "    (b0): Unit3D(\n",
       "      (conv3d): Conv3d(480, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b1a): Unit3D(\n",
       "      (conv3d): Conv3d(480, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b1b): Unit3D(\n",
       "      (conv3d): Conv3d(96, 208, kernel_size=(3, 3, 3), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(208, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b2a): Unit3D(\n",
       "      (conv3d): Conv3d(480, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b2b): Unit3D(\n",
       "      (conv3d): Conv3d(16, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b3a): MaxPool3dSamePadding(kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (b3b): Unit3D(\n",
       "      (conv3d): Conv3d(480, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_4c): InceptionModule(\n",
       "    (b0): Unit3D(\n",
       "      (conv3d): Conv3d(512, 160, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b1a): Unit3D(\n",
       "      (conv3d): Conv3d(512, 112, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b1b): Unit3D(\n",
       "      (conv3d): Conv3d(112, 224, kernel_size=(3, 3, 3), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(224, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b2a): Unit3D(\n",
       "      (conv3d): Conv3d(512, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b2b): Unit3D(\n",
       "      (conv3d): Conv3d(24, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b3a): MaxPool3dSamePadding(kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (b3b): Unit3D(\n",
       "      (conv3d): Conv3d(512, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_4d): InceptionModule(\n",
       "    (b0): Unit3D(\n",
       "      (conv3d): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b1a): Unit3D(\n",
       "      (conv3d): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b1b): Unit3D(\n",
       "      (conv3d): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b2a): Unit3D(\n",
       "      (conv3d): Conv3d(512, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b2b): Unit3D(\n",
       "      (conv3d): Conv3d(24, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b3a): MaxPool3dSamePadding(kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (b3b): Unit3D(\n",
       "      (conv3d): Conv3d(512, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_4e): InceptionModule(\n",
       "    (b0): Unit3D(\n",
       "      (conv3d): Conv3d(512, 112, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b1a): Unit3D(\n",
       "      (conv3d): Conv3d(512, 144, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b1b): Unit3D(\n",
       "      (conv3d): Conv3d(144, 288, kernel_size=(3, 3, 3), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b2a): Unit3D(\n",
       "      (conv3d): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b2b): Unit3D(\n",
       "      (conv3d): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b3a): MaxPool3dSamePadding(kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (b3b): Unit3D(\n",
       "      (conv3d): Conv3d(512, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_4f): InceptionModule(\n",
       "    (b0): Unit3D(\n",
       "      (conv3d): Conv3d(528, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b1a): Unit3D(\n",
       "      (conv3d): Conv3d(528, 160, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b1b): Unit3D(\n",
       "      (conv3d): Conv3d(160, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(320, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b2a): Unit3D(\n",
       "      (conv3d): Conv3d(528, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b2b): Unit3D(\n",
       "      (conv3d): Conv3d(32, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b3a): MaxPool3dSamePadding(kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (b3b): Unit3D(\n",
       "      (conv3d): Conv3d(528, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (MaxPool3d_5a_2x2): MaxPool3dSamePadding(kernel_size=[2, 2, 2], stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (Mixed_5b): InceptionModule(\n",
       "    (b0): Unit3D(\n",
       "      (conv3d): Conv3d(832, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b1a): Unit3D(\n",
       "      (conv3d): Conv3d(832, 160, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b1b): Unit3D(\n",
       "      (conv3d): Conv3d(160, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(320, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b2a): Unit3D(\n",
       "      (conv3d): Conv3d(832, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b2b): Unit3D(\n",
       "      (conv3d): Conv3d(32, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b3a): MaxPool3dSamePadding(kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (b3b): Unit3D(\n",
       "      (conv3d): Conv3d(832, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_5c): InceptionModule(\n",
       "    (b0): Unit3D(\n",
       "      (conv3d): Conv3d(832, 384, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b1a): Unit3D(\n",
       "      (conv3d): Conv3d(832, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b1b): Unit3D(\n",
       "      (conv3d): Conv3d(192, 384, kernel_size=(3, 3, 3), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b2a): Unit3D(\n",
       "      (conv3d): Conv3d(832, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b2b): Unit3D(\n",
       "      (conv3d): Conv3d(48, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b3a): MaxPool3dSamePadding(kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (b3b): Unit3D(\n",
       "      (conv3d): Conv3d(832, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_429",
   "language": "python",
   "name": "new_429"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
