{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9283810-1cc3-400b-ab0d-2b29ad77917f",
   "metadata": {},
   "source": [
    "### Training with augmentation Herve 1- RUNNING\n",
    "Code taken from: https://github.com/piergiaj/pytorch-i3d/blob/master/train_i3d.py \n",
    "\n",
    "Note: This code was written for PyTorch 0.3. Version 0.4 and newer may cause issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67128774-f5f4-4d89-b3d5-4c85f713aa43",
   "metadata": {},
   "source": [
    "# TO CHANGE BEFORE RUNNING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fa6755-2c81-43a1-babb-bbf7a9b06049",
   "metadata": {},
   "source": [
    "Set `augment = True` below for data to be augmented, and `false` otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cab0d1df-93a0-496a-be83-a4457fcb27ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_augment = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6545d57e-3f63-4b62-bc1e-9d2851b1b5b1",
   "metadata": {},
   "source": [
    "Set `dropout = True` below for dropout to be included, and `false` otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "372efd7e-a5fa-4ef7-8424-031cac6e06c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_dropout = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312626af-a931-43f6-95e3-0ee7bcd579ba",
   "metadata": {},
   "source": [
    "Dropout details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e38fd690-de12-4624-b7cb-b97533b764e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_details = \"layer1_p0.5\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcb25f0-c8ea-4005-a5e7-77c10ba30bc5",
   "metadata": {},
   "source": [
    "Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5377768-37ca-4c3d-bbe1-ecd857c2e29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a9ca81-852e-462a-9724-7fa9a68b4bd0",
   "metadata": {},
   "source": [
    "Set `l2 = True` below for L2 Regularization, and `false` for L1 Regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52df519f-738c-4688-9604-af1b9ee7ae1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2 = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ead160-da0c-4f59-8cea-602bc2bb3ee9",
   "metadata": {},
   "source": [
    "Set weight decay value, `wd`, for L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97b735fc-faa7-4f9a-b1dd-8d0a1cd6507c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f6e4b5-a2ee-4a71-8f7f-369b6f3f8fe1",
   "metadata": {},
   "source": [
    "Set `lambda` for L1 Regularization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4d5779b-0b34-480b-9ede-25a1b2be3379",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda1 = 1e-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa3722c-e670-46eb-89a3-859e03390432",
   "metadata": {},
   "source": [
    "Set the number of epochs in training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3eaf339-b4ae-412b-b65b-08cc7ab449a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58eb3dec-622d-493a-8a80-087b06ee59ef",
   "metadata": {},
   "source": [
    "**ALL FILES INCLUDING LOSSES AND THE MODEL WILL BE SAVED WITH THIS NAME:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ebacd34-bfbe-4236-b858-07ce0a997dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"30epochs_wd_1e-07_dropout__augmented\" means the there are 30 training epochs, weight decay is 1e-07, and that there is dropout and augmentation\n",
    "save_name = f\"{num_epochs}epochs\"\n",
    "if (not l2): save_name = save_name + \"_l1_lr_\" + str(learning_rate) + \"_ld_\" + str(lambda1) # l1 regularization\n",
    "if l2: save_name = save_name + \"_l2_lr_\" + str(learning_rate) + \"_wd_\"+ str(wd) # l2 regularization\n",
    "if is_dropout: save_name = save_name + \"_dropout_\"+dropout_details\n",
    "if is_augment: save_name = save_name + \"_augment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa088af0-9405-41a6-955d-278875749c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'30epochs_l1_lr_0.1_ld_0.01'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check save_name\n",
    "save_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b101df8e-6057-4886-a05e-e531d843ee0b",
   "metadata": {},
   "source": [
    "# CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6501e6-193d-4edf-a388-1ea00a5a9f81",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56422195-b081-4f3d-8b9a-8d541d0bad5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, precision_score\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='2'\n",
    "# os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:<1024>\"\n",
    "import sys\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "from pytorch_i3d import InceptionI3d\n",
    "import numpy as np\n",
    "import glob\n",
    "import random\n",
    "from tensorboardX import SummaryWriter\n",
    "from preprocess import run_preprocessing, get_action, holdout_set\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from PIL import Image, ImageSequence\n",
    "\n",
    "# video augmentation scripts (c) 2018 okankop\n",
    "from vidaug import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d266b6f0-d337-4648-b968-9764891edef7",
   "metadata": {},
   "source": [
    "Construct a dataset class for training the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a76d20a-aa79-438d-95f9-b62477c305b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, paths, v_names, v_labels, num_samples=16, transforms=None): # num_samples cannot be lower than 16\n",
    "        self.num_samples = num_samples\n",
    "        self.frames = dict()\n",
    "        for p in paths:\n",
    "            self.frames[p] = sorted(glob.glob(p+\"/*.jpg\"))\n",
    "        self.data = paths\n",
    "        self.video_names = v_names\n",
    "        self.video_labels = v_labels\n",
    "        self.transforms = transforms\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # get original video\n",
    "        p = self.data[idx]\n",
    "        \n",
    "        # sample frames uniformly and create newly sampled video \n",
    "        num_frames = len(self.frames[p])-1\n",
    "        sampled_idx = np.linspace(0, num_frames, self.num_samples) #get num_samples frames from the video\n",
    "        images = []\n",
    "        index = np.where(self.video_names == p.split('/')[-1]) #index of p's video name in video_names\n",
    "        label_video = self.video_labels[index] # the labels for the video\n",
    "        for i in sampled_idx:\n",
    "            image = torchvision.io.read_image(self.frames[p][int(i)])\n",
    "            small_dim = min(image.shape[-2:])\n",
    "            image = torchvision.transforms.functional.center_crop(image, (small_dim, small_dim))\n",
    "            image = torchvision.transforms.functional.resize(image, (224, 224), antialias=True)\n",
    "            images.append(image)\n",
    "        images = torch.stack(images, axis=1)\n",
    "        \n",
    "        # data augmentation \n",
    "        if (self.transforms is not None):\n",
    "            images = np.array(self.transforms(images.numpy()))\n",
    "            # normalize\n",
    "            images = (images/255)*2 - 1 # values are between -1 and 1\n",
    "            return torch.from_numpy(images).type(torch.FloatTensor), label_video \n",
    "        \n",
    "        else: \n",
    "            images = (images/255)*2 - 1 #values are between -1 and 1\n",
    "            return images, label_video \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861a4e60-ed8f-4fb4-bb3f-26b5300ece4f",
   "metadata": {},
   "source": [
    "Build transformations for data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58b94045-a2a3-44a7-80b6-6d4ff67e04d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_augment:\n",
    "    sometimes = lambda aug: Sometimes(0.4, aug) # Used to apply augmentor with 40% probability\n",
    "    rand_aug = SomeOf([ # randomly chooses two of the following augmentation methods \n",
    "        RandomRotate(degrees=10), # randomly rotates the video with a degree randomly choosen from [-10, 10] \n",
    "        RandomTranslate(x=40,y=20), # randomly shifting video in [-x, +x] and [-y, +y] coordinate\n",
    "        RandomShear(x=0.2,y=0.1), # randomly shearing video in [-x, +x] and [-y, +y] directions.\n",
    "        sometimes(HorizontalFlip()), # horizontally flip the video with 50% probability\n",
    "        sometimes(GaussianBlur(sigma=random.uniform(0.5,4))), # blur images using gaussian kernels with std. dev. = sigma\n",
    "        sometimes(ElasticTransformation(alpha=random.uniform(0,5), cval=int(random.uniform(0,255)), mode=\"nearest\")), # moving pixels locally around using displacement fields\n",
    "        sometimes(PiecewiseAffineTransform(displacement=15, displacement_kernel=1, displacement_magnification=1)), # places a regular grid of points on an image and randomly moves the neighbourhood of these point around via affine transformations\n",
    "        sometimes(Add(value=int(random.uniform(-100,100)))), # add a value to all pixel intesities in an video\n",
    "        sometimes(Multiply(value=2)), # multiply all pixel intensities with given value\n",
    "        sometimes(Multiply(value=0.5)), # multiply all pixel intensities with given value\n",
    "        sometimes(Pepper(ratio=25)), # sets a certain fraction of pixel intensities to 0\n",
    "        sometimes(Salt(ratio=25)), # sets a certain fraction of pixel intensities to 255\n",
    "    ], 2) # only select two of the above augmenters each time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4ed965-0b85-44f6-97bc-25383f510cf8",
   "metadata": {},
   "source": [
    "Extract data and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5bc4b01-a7b5-4c2a-a7dd-1d1bede0f550",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_train, video_val, label_train, label_val, unique_labels = holdout_set(0.25) #valid names and videos\n",
    "batch_size = 10 # batch size in training\n",
    "num_videos_train = len(video_train)\n",
    "num_videos_val = len(video_val)\n",
    "num_classes = len(set(label_train)) #count unique in labels\n",
    "\n",
    "video_frames_path = \"/scratch/network/hishimwe/image\" \n",
    "# only extract the videos with v_names and v_labels from preprocess.ipynb \n",
    "paths = glob.glob(video_frames_path+\"/*\")\n",
    "random.seed(0)\n",
    "random.shuffle(paths)\n",
    "\n",
    "good_paths_train = list(filter(lambda c: c.split('/')[-1] in video_train, paths)) #should only get path where good video name; not sure if this filtering will work \n",
    "good_paths_val = list(filter(lambda c: c.split('/')[-1] in video_val, paths)) # validation video paths \n",
    "\n",
    "if is_augment: d_train = dataset(paths=good_paths_train, v_names=video_train, v_labels= label_train, transforms=rand_aug)\n",
    "else: d_train = dataset(paths=good_paths_train, v_names=video_train, v_labels= label_train)\n",
    "d_val = dataset(paths=good_paths_val, v_names=video_val, v_labels= label_val)\n",
    "\n",
    "loader_train = torch.utils.data.DataLoader(d_train, shuffle=True, batch_size=batch_size, drop_last=False, num_workers=4)\n",
    "loader_val = torch.utils.data.DataLoader(d_val, shuffle=True, batch_size=batch_size, drop_last=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9aef6b0-74db-4430-b114-ff98293d9c23",
   "metadata": {},
   "source": [
    "Construct the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08457ac6-617e-4be4-a690-7970a8760b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 1.1249988079071045 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time() \n",
    "i3d = InceptionI3d(400, in_channels=3) # first input is num_classes in kinetics, this is replaced with replace_logits\n",
    "\n",
    "if is_dropout: i3d.load_state_dict(torch.load('rgb_imagenet.pt'), strict=False) #added strict = false; theoretically this lets us add layers\n",
    "else: i3d.load_state_dict(torch.load('rgb_imagenet.pt')) \n",
    "\n",
    "i3d.replace_logits(num_classes)\n",
    "i3d.cuda()\n",
    "\n",
    "print(f\"time taken: {time.time()-start_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2c9861-1c82-4c7b-a38d-ae5c9f609ee3",
   "metadata": {},
   "source": [
    "Function to evaluate model performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97a26778",
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns accuracy, f1 score, average f1, and confusion matrix for the data\n",
    "def eval_metrics(ground_truth, predictions, num_classes):\n",
    "\n",
    "    #dictionary containing the accuracy, precision, f1, avg f1, and confusion matrix for the data\n",
    "    f1 = f1_score(y_true=ground_truth, y_pred=predictions, labels=np.arange(num_classes), average=None)\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(y_true=ground_truth, y_pred=predictions),\n",
    "        \"f1\": f1,\n",
    "        \"average f1\": np.mean(f1),\n",
    "        \"confusion matrix\": confusion_matrix(y_true=ground_truth, y_pred=predictions, labels=np.arange(num_classes)),\n",
    "        \"precision\": precision_score(y_true=ground_truth, y_pred=predictions, labels=np.arange(num_classes), average=None)\n",
    "        }\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff9bb17-34d0-4a24-81c1-e9416b9f786e",
   "metadata": {},
   "source": [
    "Function to train and validate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4bbbdd8b-d941-4760-8c3d-127254351268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, optimizer, loader, num_classes, reg_type, ld=None):\n",
    "    losses = []\n",
    "    ground_truth = []\n",
    "    predictions = []\n",
    "    for data, label in loader:\n",
    "        data = data.cuda()\n",
    "        label = label.squeeze().type(torch.LongTensor).cuda()\n",
    "        num_frames = data.size(2)\n",
    "        per_frame_logits = i3d(data).mean(2)\n",
    "        preds = per_frame_logits.cpu().detach().numpy().argmax(axis=1) # convert logits into predictions for evaluating accuracy\n",
    "        \n",
    "        # calculate and save loss\n",
    "        loss = F.cross_entropy(per_frame_logits, label)\n",
    "        losses.append(loss.item()) # append to losses\n",
    "        ground_truth.extend(list(label.cpu().detach().numpy()))\n",
    "        predictions.extend(preds.tolist())\n",
    "        \n",
    "        if (not reg_type): # l1 regularization\n",
    "            params = torch.cat([p.view(-1) for p in model.parameters()]) # weights\n",
    "            norm = torch.norm(params, 1)\n",
    "            loss = loss - (ld * norm) # updating loss\n",
    "             \n",
    "        # back propagation    \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    metrics = eval_metrics(ground_truth, predictions, num_classes)   \n",
    "    return np.mean(losses), metrics # one loss per epoch and the corresponding metrics        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e46f5830-e16c-45e1-a740-50dd72575eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, num_classes):\n",
    "    losses = []\n",
    "    ground_truth = []\n",
    "    predictions = []\n",
    "    for data, label in loader:\n",
    "        data = data.cuda()\n",
    "        label = label.squeeze().type(torch.LongTensor).cuda()\n",
    "        num_frames = data.size(2)\n",
    "        per_frame_logits = i3d(data).mean(2)\n",
    "        preds = per_frame_logits.cpu().detach().numpy().argmax(axis=1) # convert logits into predictions for evaluating accuracy\n",
    "        \n",
    "        # calculate and save loss\n",
    "        loss = F.cross_entropy(per_frame_logits, label)\n",
    "        losses.append(loss.item()) # append to losses\n",
    "        ground_truth.extend(list(label.cpu().detach().numpy()))\n",
    "        predictions.extend(preds.tolist())\n",
    "        \n",
    "    metrics = eval_metrics(ground_truth, predictions, num_classes)\n",
    "    return np.mean(losses), metrics # one loss per epoch and the corresponding metrics\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7115a97f-cced-4e12-b383-46e7231c715a",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dac52e08-f69e-47a4-ac7b-bedf0c8d70ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0\n",
      "TRAINING\n",
      "Loss 3.1925109129533213\n",
      "Accuracy 0.1643075215098529\n",
      "Precision [0.05882353 0.         0.21448664 0.         0.16795866 0.15677966\n",
      " 0.10377358 0.12780269 0.1        0.05263158 0.10769231]\n",
      "VALIDATION\n",
      "Loss 3.4596562060442837\n",
      "Accuracy 0.17554076539101499\n",
      "Precision [0.125      0.         0.25       0.         0.16666667 0.08843537\n",
      " 0.05769231 0.15254237 0.1025641  0.11111111 0.03846154]\n",
      "Time taken for epoch 4: 3.6616537531216937 mins\n",
      "-----------------------------------------------------------------------\n",
      "EPOCH 5\n",
      "TRAINING\n",
      "Loss 3.4739198437027654\n",
      "Accuracy 0.15570358034970858\n",
      "Precision [0.03658537 0.         0.19818182 0.         0.14419226 0.14220183\n",
      " 0.08333333 0.14322251 0.07746479 0.02702703 0.07377049]\n",
      "VALIDATION\n",
      "Loss 3.610465953172731\n",
      "Accuracy 0.13810316139767054\n",
      "Precision [0.07692308 0.         0.18828452 0.         0.14197531 0.0625\n",
      " 0.06896552 0.11538462 0.26666667 0.17647059 0.09302326]\n",
      "Time taken for epoch 5: 3.6585108002026874 mins\n",
      "-----------------------------------------------------------------------\n",
      "EPOCH 6\n",
      "TRAINING\n",
      "Loss 3.4290243793392445\n",
      "Accuracy 0.17568692756036636\n",
      "Precision [0.0877193  0.125      0.21080792 0.         0.17391304 0.11594203\n",
      " 0.12565445 0.12179487 0.14035088 0.09375    0.07619048]\n",
      "VALIDATION\n",
      "Loss 3.4818571845362007\n",
      "Accuracy 0.16306156405990016\n",
      "Precision [0.07692308 0.         0.25396825 0.         0.16624041 0.10714286\n",
      " 0.15384615 0.18       0.09345794 0.16666667 0.09677419]\n",
      "Time taken for epoch 6: 3.6514421383539837 mins\n",
      "-----------------------------------------------------------------------\n",
      "EPOCH 7\n",
      "TRAINING\n",
      "Loss 3.517395221625669\n",
      "Accuracy 0.1745767416042187\n",
      "Precision [0.04545455 0.         0.20261438 0.         0.18013245 0.0952381\n",
      " 0.10687023 0.15116279 0.07692308 0.         0.10638298]\n",
      "VALIDATION\n",
      "Loss 3.7959799244384134\n",
      "Accuracy 0.1638935108153078\n",
      "Precision [0.03448276 0.         0.20426829 0.         0.14230769 0.07042254\n",
      " 0.11864407 0.16       0.         0.125      0.        ]\n",
      "Time taken for epoch 7: 3.6371699452400206 mins\n",
      "-----------------------------------------------------------------------\n",
      "EPOCH 8\n",
      "TRAINING\n",
      "Loss 3.8616642281619464\n",
      "Accuracy 0.16486261448792672\n",
      "Precision [0.04918033 0.         0.2032345  0.         0.16990291 0.09756098\n",
      " 0.05882353 0.11684783 0.02352941 0.         0.06818182]\n",
      "VALIDATION\n",
      "Loss 3.4954152048126725\n",
      "Accuracy 0.18136439267886856\n",
      "Precision [0.         0.         0.21578298 0.         0.15104167 0.\n",
      " 0.08571429 0.14035088 0.05882353 0.         0.03636364]\n",
      "Time taken for epoch 8: 3.6503344575564065 mins\n",
      "-----------------------------------------------------------------------\n",
      "EPOCH 9\n",
      "TRAINING\n",
      "Loss 3.6800238954063267\n",
      "Accuracy 0.17624202053844018\n",
      "Precision [0.11363636 0.         0.20841035 0.         0.14496644 0.10416667\n",
      " 0.04385965 0.13852814 0.1375     0.0625     0.14893617]\n",
      "VALIDATION\n",
      "Loss 4.124250153864711\n",
      "Accuracy 0.1497504159733777\n",
      "Precision [0.03846154 0.         0.2        0.         0.15657143 0.09183673\n",
      " 0.16666667 0.11111111 0.18181818 0.         0.        ]\n",
      "Time taken for epoch 9: 3.6403160532315573 mins\n",
      "-----------------------------------------------------------------------\n",
      "EPOCH 10\n",
      "TRAINING\n",
      "Loss 3.8776755250391868\n",
      "Accuracy 0.18012767138495697\n",
      "Precision [0.13636364 0.         0.20863309 0.         0.17174178 0.09677419\n",
      " 0.15789474 0.12037037 0.04878049 0.05263158 0.09090909]\n",
      "VALIDATION\n",
      "Loss 3.495139532837986\n",
      "Accuracy 0.15474209650582363\n",
      "Precision [0.         0.         0.16071429 0.         0.15727949 0.14705882\n",
      " 0.15384615 0.15873016 0.14285714 0.         0.        ]\n",
      "Time taken for epoch 10: 3.6359732270240785 mins\n",
      "-----------------------------------------------------------------------\n",
      "EPOCH 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jt9744/.conda/envs/cos429/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Loss 4.084185120471627\n",
      "Accuracy 0.1823480432972523\n",
      "Precision [0.         0.         0.21907601 0.         0.17326733 0.1010101\n",
      " 0.08910891 0.12722646 0.05479452 0.0625     0.03921569]\n",
      "VALIDATION\n",
      "Loss 3.7071762291853094\n",
      "Accuracy 0.194675540765391\n",
      "Precision [0.25       0.         0.21428571 0.         0.22058824 0.07407407\n",
      " 0.14285714 0.         0.0625     0.         0.        ]\n",
      "Time taken for epoch 11: 3.6507438739140827 mins\n",
      "-----------------------------------------------------------------------\n",
      "EPOCH 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jt9744/.conda/envs/cos429/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Loss 4.15687751373756\n",
      "Accuracy 0.1826255897862892\n",
      "Precision [0.14705882 0.         0.20899719 0.08333333 0.17676143 0.10743802\n",
      " 0.10843373 0.10631229 0.09259259 0.         0.1025641 ]\n",
      "VALIDATION\n",
      "Loss 3.832592469601592\n",
      "Accuracy 0.19883527454242927\n",
      "Precision [0.2        0.         0.21397849 0.         0.16083916 0.1875\n",
      " 0.075      0.22580645 0.11111111 0.         0.        ]\n",
      "Time taken for epoch 12: 3.6496246973673503 mins\n",
      "-----------------------------------------------------------------------\n",
      "EPOCH 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jt9744/.conda/envs/cos429/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Loss 4.168100578963261\n",
      "Accuracy 0.18179295031917847\n",
      "Precision [0.08571429 0.         0.20041929 0.         0.15857143 0.13483146\n",
      " 0.10526316 0.16814159 0.05       0.         0.08108108]\n",
      "VALIDATION\n",
      "Loss 4.443883483074913\n",
      "Accuracy 0.194675540765391\n",
      "Precision [0.25       0.         0.21215352 0.         0.18604651 0.\n",
      " 0.07142857 0.14814815 0.04       0.         0.        ]\n",
      "Time taken for epoch 13: 3.687841256459554 mins\n",
      "-----------------------------------------------------------------------\n",
      "EPOCH 14\n",
      "TRAINING\n",
      "Loss 4.3738785866555085\n",
      "Accuracy 0.18318068276436303\n",
      "Precision [0.04545455 0.         0.20911063 0.         0.16047548 0.12871287\n",
      " 0.08571429 0.12923077 0.07843137 0.         0.10526316]\n",
      "VALIDATION\n",
      "Loss 4.9685623754154555\n",
      "Accuracy 0.1930116472545757\n",
      "Precision [0.16666667 0.         0.20576132 0.33333333 0.15652174 0.0625\n",
      " 0.1875     0.13333333 0.125      0.         0.        ]\n",
      "Time taken for epoch 14: 3.691788983345032 mins\n",
      "-----------------------------------------------------------------------\n",
      "EPOCH 15\n",
      "TRAINING\n",
      "Loss 4.427083623376249\n",
      "Accuracy 0.18900915903413823\n",
      "Precision [0.         0.         0.20976886 0.         0.17864924 0.07317073\n",
      " 0.125      0.125      0.05405405 0.18181818 0.04347826]\n",
      "VALIDATION\n",
      "Loss 4.009955929330558\n",
      "Accuracy 0.20715474209650583\n",
      "Precision [0.08333333 0.         0.2230997  0.         0.1686747  0.1\n",
      " 0.05       0.09090909 0.         0.5        0.        ]\n",
      "Time taken for epoch 15: 3.683286738395691 mins\n",
      "-----------------------------------------------------------------------\n",
      "EPOCH 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jt9744/.conda/envs/cos429/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Loss 4.4307004768102125\n",
      "Accuracy 0.17790729947266168\n",
      "Precision [0.         0.         0.20091116 0.         0.15604396 0.1443299\n",
      " 0.07936508 0.14225941 0.02439024 0.2        0.1       ]\n",
      "VALIDATION\n",
      "Loss 4.496937647338741\n",
      "Accuracy 0.20632279534109818\n",
      "Precision [0.22222222 0.         0.22133599 0.         0.18181818 0.\n",
      " 0.15384615 0.         0.08       0.         0.        ]\n",
      "Time taken for epoch 16: 3.696544154485067 mins\n",
      "-----------------------------------------------------------------------\n",
      "EPOCH 17\n",
      "VALIDATION\n",
      "Loss 4.365154358966292\n",
      "Accuracy 0.21381031613976706\n",
      "Precision [0.         0.         0.2230997  0.         0.16666667 0.07142857\n",
      " 0.27272727 0.18965517 0.1        0.         0.33333333]\n",
      "Time taken for epoch 17: 3.6829604268074037 mins\n",
      "-----------------------------------------------------------------------\n",
      "EPOCH 18\n",
      "TRAINING\n",
      "Loss 4.710883401767699\n",
      "Accuracy 0.19122953094643352\n",
      "Precision [0.11111111 0.         0.20793269 0.         0.17138599 0.15384615\n",
      " 0.11111111 0.11282051 0.15789474 0.25       0.15625   ]\n",
      "VALIDATION\n",
      "Loss 5.386953786384961\n",
      "Accuracy 0.20382695507487522\n",
      "Precision [0.125      0.         0.22268908 0.         0.12820513 0.\n",
      " 0.06896552 0.21359223 0.05405405 0.         0.11111111]\n",
      "Time taken for epoch 18: 3.7140570481618247 mins\n",
      "-----------------------------------------------------------------------\n",
      "EPOCH 19\n",
      "TRAINING\n",
      "Loss 4.843249582187621\n",
      "Accuracy 0.19233971690258117\n",
      "Precision [0.         0.         0.20888355 0.4        0.18543046 0.078125\n",
      " 0.13541667 0.11290323 0.13636364 0.16666667 0.24324324]\n",
      "VALIDATION\n",
      "Loss 4.636099676455348\n",
      "Accuracy 0.21630615640599002\n",
      "Precision [0.         0.         0.22512563 0.         0.19512195 0.17647059\n",
      " 0.         0.1796875  0.125      0.         0.33333333]\n",
      "Time taken for epoch 19: 3.6858118653297423 mins\n",
      "-----------------------------------------------------------------------\n",
      "EPOCH 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jt9744/.conda/envs/cos429/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Loss 4.966830331202689\n",
      "Accuracy 0.18762142658895364\n",
      "Precision [0.         0.         0.20495406 0.         0.17546848 0.10526316\n",
      " 0.08333333 0.12784091 0.03225806 0.11111111 0.22727273]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jt9744/.conda/envs/cos429/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION\n",
      "Loss 5.9782613525705885\n",
      "Accuracy 0.2129783693843594\n",
      "Precision [0.         0.         0.22309198 0.         0.14893617 0.21428571\n",
      " 0.         0.22222222 0.         0.         0.2       ]\n",
      "Time taken for epoch 20: 3.6868186473846434 mins\n",
      "-----------------------------------------------------------------------\n",
      "EPOCH 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jt9744/.conda/envs/cos429/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Loss 5.314562183007639\n",
      "Accuracy 0.18734388009991673\n",
      "Precision [0.07692308 0.         0.20608108 0.         0.15937149 0.06153846\n",
      " 0.16666667 0.14117647 0.11538462 0.         0.27272727]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jt9744/.conda/envs/cos429/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION\n",
      "Loss 6.053430880396819\n",
      "Accuracy 0.19217970049916805\n",
      "Precision [0.03703704 0.         0.20591039 0.         0.14285714 0.\n",
      " 0.09677419 0.15384615 0.         0.         0.        ]\n",
      "Time taken for epoch 21: 3.6877763708432516 mins\n",
      "-----------------------------------------------------------------------\n",
      "EPOCH 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jt9744/.conda/envs/cos429/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Loss 5.5315894581934755\n",
      "Accuracy 0.19539272828198723\n",
      "Precision [0.16666667 0.         0.20881671 0.         0.17320704 0.10869565\n",
      " 0.14285714 0.14018692 0.07142857 0.         0.19047619]\n",
      "VALIDATION\n",
      "Loss 5.432086864778818\n",
      "Accuracy 0.2096505823627288\n",
      "Precision [0.09090909 0.         0.21792453 0.         0.225      0.\n",
      " 0.         0.16129032 0.         0.         0.5       ]\n",
      "Time taken for epoch 22: 3.6809189279874164 mins\n",
      "-----------------------------------------------------------------------\n",
      "EPOCH 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jt9744/.conda/envs/cos429/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Loss 4.833652178666599\n",
      "Accuracy 0.1945600888148765\n",
      "Precision [0.07692308 0.         0.20757072 0.         0.17703349 0.15254237\n",
      " 0.07692308 0.16289593 0.13043478 0.         0.27272727]\n",
      "VALIDATION\n",
      "Loss 6.477335900314583\n",
      "Accuracy 0.2079866888519135\n",
      "Precision [0.         0.         0.21515435 0.         0.18333333 0.14285714\n",
      " 0.125      0.19354839 0.         0.         0.        ]\n",
      "Time taken for epoch 23: 3.7085154175758364 mins\n",
      "-----------------------------------------------------------------------\n",
      "EPOCH 24\n",
      "TRAINING\n",
      "Loss 4.9689054482531345\n",
      "Accuracy 0.19511518179295032\n",
      "Precision [0.25       0.         0.21610845 0.14285714 0.15336658 0.0754717\n",
      " 0.13953488 0.14414414 0.05882353 0.125      0.26086957]\n",
      "VALIDATION\n",
      "Loss 5.592227413634624\n",
      "Accuracy 0.19550748752079866\n",
      "Precision [0.         0.         0.20790216 0.         0.12345679 0.03225806\n",
      " 0.33333333 0.25       0.         0.         0.        ]\n",
      "Time taken for epoch 24: 3.71129424571991 mins\n",
      "-----------------------------------------------------------------------\n",
      "EPOCH 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jt9744/.conda/envs/cos429/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Loss 5.672179143844879\n",
      "Accuracy 0.18151540383014156\n",
      "Precision [0.04761905 0.         0.19682294 0.         0.15059445 0.12244898\n",
      " 0.11428571 0.13513514 0.05       0.         0.2173913 ]\n",
      "VALIDATION\n",
      "Loss 6.269763348516354\n",
      "Accuracy 0.15806988352745424\n",
      "Precision [0.         0.         0.21428571 0.         0.15869981 0.14285714\n",
      " 0.125      0.04       0.         0.         0.33333333]\n",
      "Time taken for epoch 25: 3.7150313019752503 mins\n",
      "-----------------------------------------------------------------------\n",
      "EPOCH 26\n",
      "TRAINING\n",
      "Loss 5.411199210423182\n",
      "Accuracy 0.1806827643630308\n",
      "Precision [0.18181818 0.         0.20345964 0.         0.15322581 0.09677419\n",
      " 0.09677419 0.08823529 0.03703704 0.         0.4375    ]\n",
      "VALIDATION\n",
      "Loss 6.456326726054357\n",
      "Accuracy 0.20133111480865223\n",
      "Precision [0.         0.         0.21243043 0.         0.19047619 0.\n",
      " 0.         0.25       0.05263158 0.         0.        ]\n",
      "Time taken for epoch 26: 3.7076921661694846 mins\n",
      "-----------------------------------------------------------------------\n",
      "EPOCH 27\n",
      "TRAINING\n",
      "Loss 5.585688322204632\n",
      "Accuracy 0.19011934499028588\n",
      "Precision [0.23529412 0.         0.20675784 0.         0.15242494 0.13157895\n",
      " 0.14705882 0.16346154 0.04545455 0.         0.28      ]\n",
      "VALIDATION\n",
      "Loss 6.345881605936476\n",
      "Accuracy 0.1589018302828619\n",
      "Precision [0.         0.         0.25373134 0.         0.15642458 0.125\n",
      " 0.07142857 0.09090909 0.33333333 0.         0.        ]\n",
      "Time taken for epoch 27: 3.6992188413937885 mins\n",
      "-----------------------------------------------------------------------\n",
      "EPOCH 28\n",
      "TRAINING\n",
      "Loss 6.056825450582847\n",
      "Accuracy 0.18290313627532612\n",
      "Precision [0.         0.         0.198      0.         0.16064757 0.11864407\n",
      " 0.13043478 0.10179641 0.07142857 0.         0.33333333]\n",
      "VALIDATION\n",
      "Loss 5.5038541437180575\n",
      "Accuracy 0.20382695507487522\n",
      "Precision [0.         0.         0.21435143 0.         0.28571429 0.05\n",
      " 0.         0.06       0.14285714 0.         0.16666667]\n",
      "Time taken for epoch 28: 3.7113951643308005 mins\n",
      "-----------------------------------------------------------------------\n",
      "EPOCH 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jt9744/.conda/envs/cos429/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Loss 5.799484047863292\n",
      "Accuracy 0.19122953094643352\n",
      "Precision [0.         0.         0.20742534 0.         0.17253521 0.03508772\n",
      " 0.0625     0.10852713 0.0625     0.         0.34615385]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jt9744/.conda/envs/cos429/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION\n",
      "Loss 4.985834568985237\n",
      "Accuracy 0.16306156405990016\n",
      "Precision [0.         0.         0.22222222 0.         0.16211293 0.11111111\n",
      " 0.125      0.15384615 0.         0.         0.        ]\n",
      "Time taken for epoch 29: 3.7202760140101114 mins\n",
      "-----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jt9744/.conda/envs/cos429/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# set up gradient descent params\n",
    "\n",
    "if (l2): # l2 regularization \n",
    "    optimizer = optim.SGD(i3d.parameters(), lr=learning_rate, momentum=0.9, weight_decay=wd) # weight_decay = l2 regularization\n",
    "    lr_sched = optim.lr_scheduler.MultiStepLR(optimizer, [300, 1000])\n",
    "else: # l1 regularization\n",
    "    optimizer = optim.SGD(i3d.parameters(), lr=learning_rate, momentum=0.9) \n",
    "    lr_sched = optim.lr_scheduler.MultiStepLR(optimizer, [300, 1000])\n",
    "\n",
    "\n",
    "# save performance\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "train_precisions = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "val_precisions = []\n",
    "\n",
    "# train\n",
    "for e in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(\"EPOCH\", e)\n",
    "    \n",
    "    # training\n",
    "    loss_train, metrics_train = training(model=i3d, optimizer=optimizer, loader=loader_train, num_classes=num_classes, reg_type=l2, ld=lambda1)\n",
    "    train_losses.append(loss_train)\n",
    "    train_accuracies.append(metrics_train[\"accuracy\"])\n",
    "    train_precisions.append(metrics_train[\"precision\"])\n",
    "    \n",
    "    print(\"TRAINING\")\n",
    "    print(\"Loss\", loss_train)\n",
    "    print(\"Accuracy\", metrics_train[\"accuracy\"])\n",
    "    print(\"Precision\", metrics_train[\"precision\"])\n",
    "    \n",
    "    # validation \n",
    "    loss_val, metrics_val = evaluate(model=i3d, loader=loader_val, num_classes=num_classes)\n",
    "    val_losses.append(loss_val)\n",
    "    val_accuracies.append(metrics_val[\"accuracy\"])\n",
    "    val_precisions.append(metrics_val[\"precision\"])\n",
    "    \n",
    "    np.savetxt('/home/jt9744/COS429/429_Final/herve_losses/train/train_'+ save_name, np.array(train_losses), delimiter=\",\")\n",
    "    np.savetxt('/home/jt9744/COS429/429_Final/herve_losses/val/val_' + save_name, np.array(val_losses), delimiter=\",\")\n",
    "\n",
    "    np.savetxt('/home/jt9744/COS429/429_Final/herve_accuracies/train/train_'+save_name, np.array(train_accuracies), delimiter=\",\")\n",
    "    np.savetxt('/home/jt9744/COS429/429_Final/herve_accuracies/val/val_'+save_name, np.array(val_accuracies), delimiter=\",\")\n",
    "\n",
    "    np.savetxt('/home/jt9744/COS429/429_Final/herve_precisions/train/train_'+save_name, np.array(train_precisions), delimiter=\",\")\n",
    "    np.savetxt('/home/jt9744/COS429/429_Final/herve_precisions/val/val_'+save_name, np.array(val_precisions), delimiter=\",\")\n",
    "    \n",
    "    print(\"VALIDATION\")\n",
    "    print(\"Loss\", loss_val)\n",
    "    print(\"Accuracy\", metrics_val[\"accuracy\"])\n",
    "    print(\"Precision\", metrics_val[\"precision\"])\n",
    "        \n",
    "    print(f\"Time taken for epoch {e}: {(time.time()-start_time)/60} mins\")\n",
    "    print(\"-----------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fbbacae8-cb59-4e82-8f8b-7581ab67c6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_losses: [3.85413773766515, 3.110879807921328, 3.041332032541819, 3.111503958041648, 3.1925109129533213, 3.4739198437027654, 3.4290243793392445, 3.517395221625669, 3.8616642281619464, 3.6800238954063267, 3.8776755250391868, 4.084185120471627, 4.15687751373756, 4.168100578963261, 4.3738785866555085, 4.427083623376249, 4.4307004768102125, 4.358303716308193, 4.710883401767699, 4.843249582187621, 4.966830331202689, 5.314562183007639, 5.5315894581934755, 4.833652178666599, 4.9689054482531345, 5.672179143844879, 5.411199210423182, 5.585688322204632, 6.056825450582847, 5.799484047863292]\n",
      "val_losses: [3.0663892405092223, 2.8594222659907067, 3.1467551997870453, 3.011469419337501, 3.4596562060442837, 3.610465953172731, 3.4818571845362007, 3.7959799244384134, 3.4954152048126725, 4.124250153864711, 3.495139532837986, 3.7071762291853094, 3.832592469601592, 4.443883483074913, 4.9685623754154555, 4.009955929330558, 4.496937647338741, 4.365154358966292, 5.386953786384961, 4.636099676455348, 5.9782613525705885, 6.053430880396819, 5.432086864778818, 6.477335900314583, 5.592227413634624, 6.269763348516354, 6.456326726054357, 6.345881605936476, 5.5038541437180575, 4.985834568985237]\n",
      "train_accuracies: [0.1729114626699972, 0.1623646960865945, 0.1659728004440744, 0.15265056897030252, 0.1643075215098529, 0.15570358034970858, 0.17568692756036636, 0.1745767416042187, 0.16486261448792672, 0.17624202053844018, 0.18012767138495697, 0.1823480432972523, 0.1826255897862892, 0.18179295031917847, 0.18318068276436303, 0.18900915903413823, 0.17790729947266168, 0.18540105467665835, 0.19122953094643352, 0.19233971690258117, 0.18762142658895364, 0.18734388009991673, 0.19539272828198723, 0.1945600888148765, 0.19511518179295032, 0.18151540383014156, 0.1806827643630308, 0.19011934499028588, 0.18290313627532612, 0.19122953094643352]\n",
      "val_accuracies: [0.1788685524126456, 0.1622296173044925, 0.15307820299500832, 0.16805324459234608, 0.17554076539101499, 0.13810316139767054, 0.16306156405990016, 0.1638935108153078, 0.18136439267886856, 0.1497504159733777, 0.15474209650582363, 0.194675540765391, 0.19883527454242927, 0.194675540765391, 0.1930116472545757, 0.20715474209650583, 0.20632279534109818, 0.21381031613976706, 0.20382695507487522, 0.21630615640599002, 0.2129783693843594, 0.19217970049916805, 0.2096505823627288, 0.2079866888519135, 0.19550748752079866, 0.15806988352745424, 0.20133111480865223, 0.1589018302828619, 0.20382695507487522, 0.16306156405990016]\n"
     ]
    }
   ],
   "source": [
    "print(f\"train_losses: {train_losses}\")\n",
    "print(f\"val_losses: {val_losses}\")\n",
    "print(f\"train_accuracies: {train_accuracies}\")\n",
    "print(f\"val_accuracies: {val_accuracies}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dbbf5c-9b13-4545-926a-59c5dcbc0ec3",
   "metadata": {},
   "source": [
    "Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7409064-503b-4701-9739-636f2636e6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/home/jt9744/COS429/429_Final/herve_models_trained/\" + save_name \n",
    "torch.save(i3d, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df4bdf3-f866-4a5a-a02d-be2de8c3cada",
   "metadata": {},
   "source": [
    "Check saved output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23ba1e1c-03d6-4bf3-b004-2041ecd74a2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InceptionI3d(\n",
       "  (avg_pool): AvgPool3d(kernel_size=[2, 7, 7], stride=(1, 1, 1), padding=0)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (logits): Unit3D(\n",
       "    (conv3d): Conv3d(1024, 11, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "  )\n",
       "  (Conv3d_1a_7x7): Unit3D(\n",
       "    (conv3d): Conv3d(3, 64, kernel_size=(7, 7, 7), stride=(2, 2, 2), bias=False)\n",
       "    (bn): BatchNorm3d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (MaxPool3d_2a_3x3): MaxPool3dSamePadding(kernel_size=[1, 3, 3], stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (Conv3d_2b_1x1): Unit3D(\n",
       "    (conv3d): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "    (bn): BatchNorm3d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv3d_2c_3x3): Unit3D(\n",
       "    (conv3d): Conv3d(64, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), bias=False)\n",
       "    (bn): BatchNorm3d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (MaxPool3d_3a_3x3): MaxPool3dSamePadding(kernel_size=[1, 3, 3], stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (Mixed_3b): InceptionModule(\n",
       "    (b0): Unit3D(\n",
       "      (conv3d): Conv3d(192, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b1a): Unit3D(\n",
       "      (conv3d): Conv3d(192, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b1b): Unit3D(\n",
       "      (conv3d): Conv3d(96, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b2a): Unit3D(\n",
       "      (conv3d): Conv3d(192, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b2b): Unit3D(\n",
       "      (conv3d): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b3a): MaxPool3dSamePadding(kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (b3b): Unit3D(\n",
       "      (conv3d): Conv3d(192, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_3c): InceptionModule(\n",
       "    (b0): Unit3D(\n",
       "      (conv3d): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b1a): Unit3D(\n",
       "      (conv3d): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b1b): Unit3D(\n",
       "      (conv3d): Conv3d(128, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b2a): Unit3D(\n",
       "      (conv3d): Conv3d(256, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b2b): Unit3D(\n",
       "      (conv3d): Conv3d(32, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b3a): MaxPool3dSamePadding(kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (b3b): Unit3D(\n",
       "      (conv3d): Conv3d(256, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (MaxPool3d_4a_3x3): MaxPool3dSamePadding(kernel_size=[3, 3, 3], stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (Mixed_4b): InceptionModule(\n",
       "    (b0): Unit3D(\n",
       "      (conv3d): Conv3d(480, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b1a): Unit3D(\n",
       "      (conv3d): Conv3d(480, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b1b): Unit3D(\n",
       "      (conv3d): Conv3d(96, 208, kernel_size=(3, 3, 3), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(208, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b2a): Unit3D(\n",
       "      (conv3d): Conv3d(480, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b2b): Unit3D(\n",
       "      (conv3d): Conv3d(16, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b3a): MaxPool3dSamePadding(kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (b3b): Unit3D(\n",
       "      (conv3d): Conv3d(480, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_4c): InceptionModule(\n",
       "    (b0): Unit3D(\n",
       "      (conv3d): Conv3d(512, 160, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b1a): Unit3D(\n",
       "      (conv3d): Conv3d(512, 112, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b1b): Unit3D(\n",
       "      (conv3d): Conv3d(112, 224, kernel_size=(3, 3, 3), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(224, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b2a): Unit3D(\n",
       "      (conv3d): Conv3d(512, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b2b): Unit3D(\n",
       "      (conv3d): Conv3d(24, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b3a): MaxPool3dSamePadding(kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (b3b): Unit3D(\n",
       "      (conv3d): Conv3d(512, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_4d): InceptionModule(\n",
       "    (b0): Unit3D(\n",
       "      (conv3d): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b1a): Unit3D(\n",
       "      (conv3d): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b1b): Unit3D(\n",
       "      (conv3d): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b2a): Unit3D(\n",
       "      (conv3d): Conv3d(512, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b2b): Unit3D(\n",
       "      (conv3d): Conv3d(24, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b3a): MaxPool3dSamePadding(kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (b3b): Unit3D(\n",
       "      (conv3d): Conv3d(512, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_4e): InceptionModule(\n",
       "    (b0): Unit3D(\n",
       "      (conv3d): Conv3d(512, 112, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b1a): Unit3D(\n",
       "      (conv3d): Conv3d(512, 144, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b1b): Unit3D(\n",
       "      (conv3d): Conv3d(144, 288, kernel_size=(3, 3, 3), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b2a): Unit3D(\n",
       "      (conv3d): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b2b): Unit3D(\n",
       "      (conv3d): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b3a): MaxPool3dSamePadding(kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (b3b): Unit3D(\n",
       "      (conv3d): Conv3d(512, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_4f): InceptionModule(\n",
       "    (b0): Unit3D(\n",
       "      (conv3d): Conv3d(528, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b1a): Unit3D(\n",
       "      (conv3d): Conv3d(528, 160, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b1b): Unit3D(\n",
       "      (conv3d): Conv3d(160, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(320, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b2a): Unit3D(\n",
       "      (conv3d): Conv3d(528, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b2b): Unit3D(\n",
       "      (conv3d): Conv3d(32, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b3a): MaxPool3dSamePadding(kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (b3b): Unit3D(\n",
       "      (conv3d): Conv3d(528, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (MaxPool3d_5a_2x2): MaxPool3dSamePadding(kernel_size=[2, 2, 2], stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (Mixed_5b): InceptionModule(\n",
       "    (b0): Unit3D(\n",
       "      (conv3d): Conv3d(832, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b1a): Unit3D(\n",
       "      (conv3d): Conv3d(832, 160, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b1b): Unit3D(\n",
       "      (conv3d): Conv3d(160, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(320, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b2a): Unit3D(\n",
       "      (conv3d): Conv3d(832, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b2b): Unit3D(\n",
       "      (conv3d): Conv3d(32, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b3a): MaxPool3dSamePadding(kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (b3b): Unit3D(\n",
       "      (conv3d): Conv3d(832, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_5c): InceptionModule(\n",
       "    (b0): Unit3D(\n",
       "      (conv3d): Conv3d(832, 384, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b1a): Unit3D(\n",
       "      (conv3d): Conv3d(832, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b1b): Unit3D(\n",
       "      (conv3d): Conv3d(192, 384, kernel_size=(3, 3, 3), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b2a): Unit3D(\n",
       "      (conv3d): Conv3d(832, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b2b): Unit3D(\n",
       "      (conv3d): Conv3d(48, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b3a): MaxPool3dSamePadding(kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (b3b): Unit3D(\n",
       "      (conv3d): Conv3d(832, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cos429",
   "language": "python",
   "name": "cos429"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
